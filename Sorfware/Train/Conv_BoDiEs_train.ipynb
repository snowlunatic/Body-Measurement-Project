{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9VWUL1jRRwU"
   },
   "source": [
    "# Conv_BoDiEs 학습\n",
    "Dataset: https://skeletex.xyz/portfolio/datasets\n",
    "(Estimation of Anthopometric human body measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 import, 데이터 경로 지정정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47087,
     "status": "ok",
     "timestamp": 1732364907099,
     "user": {
      "displayName": "임순호",
      "userId": "03070420375160077618"
     },
     "user_tz": -540
    },
    "id": "g_4hRV26Q28Y",
    "outputId": "52eab05d-56d4-447f-d440-0f3a3e0a75fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Using cuda device\n",
      "Device name: Tesla T4\n",
      "extraction completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "# 구글 드라이브 마운트 - Colab 사용할 경우\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 훈련을 위한 CPU 또는 GPU 장치 가져오기\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device} 장치를 사용 중입니다\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'장치 이름: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "# 이미지 ZIP 파일 압축 해제 / 드라이버에서의 위치를 지정 /Colab을 사용하지 않을 경우 local에서의 데이터 경로 지정정\n",
    "zip_file_path = '/content/drive/MyDrive/Conv_BoDiEs/dataset/imgs_female.zip'  # 압축 해제할 파일 경로\n",
    "extract_dir = '/content/images_female'  # 압축 해제할 디렉토리\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print('Extraction completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로더 클래스 생성 및 학습/시험 데이터 분리리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459581,
     "status": "ok",
     "timestamp": 1732365482591,
     "user": {
      "displayName": "임순호",
      "userId": "03070420375160077618"
     },
     "user_tz": -540
    },
    "id": "fwX7AStmQ97Z",
    "outputId": "181f8b10-2ff5-40b9-ecb5-9410fb7647d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 40000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 클래스 정의 - 이미지와 라벨을 하나로 묶어서 Dataloader 생성성\n",
    "class BodyMeasurementsDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file, header=None)  # header=None 옵션을 사용해 첫 번째 행도 데이터로 입력\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 인덱스 기반으로 이미지 이름 생성\n",
    "        img_name = os.path.join(self.img_dir, f\"{idx:06d}.png\")\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        label = torch.tensor(self.data_frame.iloc[idx].values, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 데이터 전처리 및 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),  # 이미지를 200x200 크기로 리사이즈\n",
    "    transforms.ToTensor()           # 이미지를 Tensor로 변환\n",
    "])\n",
    "\n",
    "# CSV 파일 경로와 이미지 디렉토리 설정\n",
    "csv_file = '/content/drive/MyDrive/Conv_BoDiEs/dataset/Annotations/bodymeasurements_f.csv'  # CSV 파일 경로\n",
    "img_dir = '/content/images_female/imgs_female'   # 압축 해제된 이미지 디렉토리 경로\n",
    "\n",
    "# 전체 데이터셋을 로드\n",
    "dataset = BodyMeasurementsDataset(csv_file=csv_file, img_dir=img_dir, transform=transform)\n",
    "\n",
    "# 학습 데이터와 시험 데이터로 나눔\n",
    "train_size = int(0.8 * len(dataset))  # 학습 데이터 비율 (80%)\n",
    "test_size = len(dataset) - train_size  # 시험 데이터 비율 (20%)\n",
    "\n",
    "# train_size는 40000, test_size는 10000이 됨 \n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 학습용 DataLoader와 시험용 DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Google Drive에 저장할 디렉토리 생성 / Colab에서 실행하지 않을 경우 drive_path를 local 폴더로 지정 \n",
    "drive_path = '/content/drive/My Drive/dataloader'\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# DataLoader의 데이터를 Google Drive에 저장 / Colab에서 실행하지 않을 경우 drive_path를 local 폴더로 지정 \n",
    "train_data_path = os.path.join(drive_path, 'train_data_fe_grayscale.pth')\n",
    "test_data_path = os.path.join(drive_path, 'test_data_fe_grayscale.pth')\n",
    "\n",
    "torch.save([data for data in train_loader], train_data_path)\n",
    "torch.save([data for data in test_loader], test_data_path)\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \"Conv_BoDiES\" 모델 아키텍처 생성성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1732365483203,
     "user": {
      "displayName": "임순호",
      "userId": "03070420375160077618"
     },
     "user_tz": -540
    },
    "id": "esvi97rRRHix"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Conv_BoDiEs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_BoDiEs, self).__init__()\n",
    "\n",
    "        # 첫 번째 컨볼루션 레이어\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 두 번째 컨볼루션 레이어\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 세 번째 컨볼루션 레이어\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 네 번째 컨볼루션 레이어\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 평탄화된 크기 계산 (컨볼루션 후 크기)\n",
    "        flattened_size = 32 * 12 * 12\n",
    "\n",
    "        # 첫 번째 완전 연결 레이어\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 두 번째 완전 연결 레이어\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 생성 및 사용\n",
    "model = Conv_BoDiEs().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEi_2X44RMhw",
    "outputId": "e4214aea-fb4f-48ca-ac72-5cc218b5469a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.6073\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [2/100], Loss: 1.5417\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [3/100], Loss: 1.3527\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [4/100], Loss: 1.2150\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [5/100], Loss: 1.1248\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [6/100], Loss: 1.0291\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [7/100], Loss: 0.9664\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [8/100], Loss: 0.9040\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [9/100], Loss: 0.8500\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [10/100], Loss: 0.8118\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [11/100], Loss: 0.7769\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [12/100], Loss: 0.7475\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [13/100], Loss: 0.7301\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [14/100], Loss: 0.7091\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [15/100], Loss: 0.6956\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [16/100], Loss: 0.6842\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [17/100], Loss: 0.6718\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [18/100], Loss: 0.6611\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [19/100], Loss: 0.6468\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [20/100], Loss: 0.6361\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [21/100], Loss: 0.6302\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [22/100], Loss: 0.6279\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [23/100], Loss: 0.6166\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [24/100], Loss: 0.6067\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [25/100], Loss: 0.6053\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [26/100], Loss: 0.5945\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [27/100], Loss: 0.5881\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [28/100], Loss: 0.5841\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [29/100], Loss: 0.5734\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [30/100], Loss: 0.5734\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [31/100], Loss: 0.5678\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [32/100], Loss: 0.5617\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [33/100], Loss: 0.5560\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [34/100], Loss: 0.5561\n",
      "Epoch [35/100], Loss: 0.5511\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [36/100], Loss: 0.5469\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [37/100], Loss: 0.5453\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n",
      "Epoch [38/100], Loss: 0.5417\n",
      "Best model saved to /content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 10  # 조기 종료를 위한 인내심 설정\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    epoch_loss = 0.0\n",
    "    for images, labels in train_loader:  # 학습용 DataLoader에서 배치 데이터를 가져옴\n",
    "        images, labels = images.to(device), labels.to(device)  # 데이터를 현재 장치(CPU/GPU)로 이동\n",
    "        optimizer.zero_grad()  # 옵티마이저의 기울기를 초기화\n",
    "\n",
    "        outputs = model(images)  # 모델을 통해 예측값을 계산\n",
    "        loss = criterion(outputs, labels)  # 계산된 예측값과 실제 레이블로 손실 계산\n",
    "\n",
    "        loss.backward()  # 손실에 대한 기울기를 계산(역전파)\n",
    "        optimizer.step()  # 계산된 기울기를 사용하여 모델의 가중치를 업데이트\n",
    "\n",
    "        epoch_loss += loss.item()  # 에폭 손실에 배치 손실을 더함\n",
    "\n",
    "    epoch_loss /= len(train_loader)  # 평균 에폭 손실 계산\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        counter = 0\n",
    "        # 최적의 모델 상태를 저장 / Colab 아닐시 local 경로로로 변경\n",
    "        best_model_save_path = '/content/drive/MyDrive/Conv_BoDiEs/Best_Conv_BoDiEs_model_fe_grayscale.pth'\n",
    "        torch.save(model.state_dict(), best_model_save_path)\n",
    "        print(f'최적 모델 저장: {best_model_save_path}')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:  # 설정된 인내심을 초과하면 학습 중단\n",
    "            print(f'조기 종료, Epoch: {epoch+1}')\n",
    "            break\n",
    "\n",
    "# 학습 완료 후 최종 모델 저장 / Colab 아닐시 local 경로로로 변경\n",
    "final_model_save_path = '/content/drive/MyDrive/Conv_BoDiEs/Final_Conv_BoDiEs_model_fe_grayscale.pth'\n",
    "torch.save(model.state_dict(), final_model_save_path)\n",
    "print(f'최종 모델 저장: {final_model_save_path}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMXsFCjMNG4u8rv/xGKKB4i",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
