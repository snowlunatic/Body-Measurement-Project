{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv_BoDiEs Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37995,
     "status": "ok",
     "timestamp": 1727590720706,
     "user": {
      "displayName": "임순호",
      "userId": "03070420375160077618"
     },
     "user_tz": -540
    },
    "id": "tx2T0G2pm8SZ",
    "outputId": "0dcbcd82-c137-414e-8802-1858a0177105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Using cuda device\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Google 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Get CPU or GPU device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Device name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conv_BoDiEs 모델 정의(학습과 똑같이이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1727590727441,
     "user": {
      "displayName": "임순호",
      "userId": "03070420375160077618"
     },
     "user_tz": -540
    },
    "id": "24ii5VPanInx"
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class Conv_BoDiEs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_BoDiEs, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Input size is (b, 32, 12, 12) after conv4 and maxpool\n",
    "        flattened_size = 32 * 12 * 12\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "model = Conv_BoDiEs().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습과정에서 저장장한 test 데이터로더 경로지정 및 시험결과 저장장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30360,
     "status": "ok",
     "timestamp": 1727590850716,
     "user": {
      "displayName": "임순호",
      "userId": "03070420375160077618"
     },
     "user_tz": -540
    },
    "id": "B7L6MoynnL1Q",
    "outputId": "eab8b55f-9cab-4249-ca1b-020b682871da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d066d4c07f2e>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_loader = torch.load(test_data_path)\n",
      "<ipython-input-4-d066d4c07f2e>:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5537\n",
      "Test results saved to /content/drive/MyDrive/test_results/test_predictions_grayscale_check.csv\n"
     ]
    }
   ],
   "source": [
    "# 저장된 DataLoader 객체 로드\n",
    "test_data_path = '/content/drive/MyDrive/dataloader/test_data_grayscale.pth'\n",
    "test_loader = torch.load(test_data_path)\n",
    "\n",
    "# 모델 로드\n",
    "model_path = '/content/drive/MyDrive/Conv_BoDiEs/train_results/Best_Conv_BoDiEs_model_1st_grayscale.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # 평가 모드 설정\n",
    "\n",
    "# 테스트\n",
    "criterion = nn.L1Loss()  # 손실 함수\n",
    "\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# 파일 경로 설정\n",
    "result_file_path = '/content/drive/MyDrive/test_results/test_predictions_grayscale_check.csv'\n",
    "\n",
    "# 디렉토리 생성 (필요시)\n",
    "Path(result_file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CSV 파일에 쓰기\n",
    "with open(result_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Actual', 'Prediction'])\n",
    "    for actual, prediction in zip(actuals, predictions):\n",
    "        writer.writerow([actual, prediction])\n",
    "\n",
    "print(f'Test results saved to {result_file_path}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP33AkHPd+hFjpWA9ntF1fG",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
